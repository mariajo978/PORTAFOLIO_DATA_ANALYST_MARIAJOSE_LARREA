{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operaciones avanzadas con DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descripción de las variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El dataset, obtenido de <a target = \"_blank\" href=\"https://www.transtats.bts.gov/Fields.asp?Table_ID=236\">este link</a> está compuesto por las siguientes variables referidas siempre al año 2018:\n",
    "\n",
    "1. **Month** 1-4\n",
    "2. **DayofMonth** 1-31\n",
    "3. **DayOfWeek** 1 (Monday) - 7 (Sunday)\n",
    "4. **FlightDate** fecha del vuelo\n",
    "5. **Origin** código IATA del aeropuerto de origen\n",
    "6. **OriginCity** ciudad donde está el aeropuerto de origen\n",
    "7. **Dest** código IATA del aeropuerto de destino\n",
    "8. **DestCity** ciudad donde está el aeropuerto de destino  \n",
    "9. **DepTime** hora real de salida (local, hhmm)\n",
    "10. **DepDelay** retraso a la salida, en minutos\n",
    "11. **ArrTime** hora real de llegada (local, hhmm)\n",
    "12. **ArrDelay** retraso a la llegada, en minutos: se considera que un vuelo ha llegado \"on time\" si aterrizó menos de 15 minutos más tarde de la hora prevista en el Computerized Reservations Systems (CRS).\n",
    "13. **Cancelled** si el vuelo fue cancelado (1 = sí, 0 = no)\n",
    "14. **CancellationCode** razón de cancelación (A = aparato, B = tiempo atmosférico, C = NAS, D = seguridad)\n",
    "15. **Diverted** si el vuelo ha sido desviado (1 = sí, 0 = no)\n",
    "16. **ActualElapsedTime** tiempo real invertido en el vuelo\n",
    "17. **AirTime** en minutos\n",
    "18. **Distance** en millas\n",
    "19. **CarrierDelay** en minutos: El retraso del transportista está bajo el control del transportista aéreo. Ejemplos de sucesos que pueden determinar el retraso del transportista son: limpieza de la aeronave, daño de la aeronave, espera de la llegada de los pasajeros o la tripulación de conexión, equipaje, impacto de un pájaro, carga de equipaje, servicio de comidas, computadora, equipo del transportista, problemas legales de la tripulación (descanso del piloto o acompañante) , daños por mercancías peligrosas, inspección de ingeniería, abastecimiento de combustible, pasajeros discapacitados, tripulación retrasada, servicio de inodoros, mantenimiento, ventas excesivas, servicio de agua potable, denegación de viaje a pasajeros en mal estado, proceso de embarque muy lento, equipaje de mano no válido, retrasos de peso y equilibrio.\n",
    "20. **WeatherDelay** en minutos: causado por condiciones atmosféricas extremas o peligrosas, previstas o que se han manifestado antes del despegue, durante el viaje, o a la llegada.\n",
    "21. **NASDelay** en minutos: retraso causado por el National Airspace System (NAS) por motivos como condiciones meteorológicas (perjudiciales pero no extremas), operaciones del aeropuerto, mucho tráfico aéreo, problemas con los controladores aéreos, etc.\n",
    "22. **SecurityDelay** en minutos: causado por la evacuación de una terminal, re-embarque de un avión debido a brechas en la seguridad, fallos en dispositivos del control de seguridad, colas demasiado largas en el control de seguridad, etc.\n",
    "23. **LateAircraftDelay** en minutos: debido al propio retraso del avión al llegar, problemas para conseguir aterrizar en un aeropuerto a una hora más tardía de la que estaba prevista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "# Leemos los datos y quitamos filas con NA y convertimos a numéricas las columnas inferidas incorrectamente\n",
    "flightsDF = spark.read\\\n",
    "                 .option(\"header\", \"true\")\\\n",
    "                 .option(\"inferSchema\", \"true\")\\\n",
    "                 .csv(\"gs://ucmbucket2023/datos/flights-jan-apr-2018.csv\")\n",
    "\n",
    "# Convertimos a enteros y re-categorizamos ArrDelay en una nueva columna ArrDelayCat\n",
    "# None (< 15 min), Slight(entre 15 y 60 min), Huge (> 60 min)\n",
    "\n",
    "cleanFlightsDF = flightsDF.withColumn(\"ArrDelayCat\", F.when(F.col(\"ArrDelay\") < 15, \"None\")\\\n",
    "                                                      .when((F.col(\"ArrDelay\") >= 15) & (F.col(\"ArrDelay\") < 60), \"Slight\")\\\n",
    "                                                      .otherwise(\"Huge\"))\\\n",
    "                           .cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hagamos algunas preguntas a los datos para obtener conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imaginemos que somos los dueños de una web de viajes que rastrea internet en busca de vuelos en agencias y otras páginas, los compara y recomienda el más adecuado para el aeropuerto. Junto con esta recomendación, querríamos dar también información sobre vuelos fiables y no fiables en lo que respecta a la puntualidad. Esto depende de muchos factores, como el origen y destino, duración del vuelo, hora del día, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agrupación y agregaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<p><b>PREGUNTA</b>: ¿Cuáles son los vuelos (origen, destino) con mayor retraso medio? ¿Cuántos vuelos existen entre cada par de aeropuertos?</p>  Guardar el resultado en la variable averageDelayOriginDest\n",
    "<p><b>PISTA</b>: Tras hacer las agregaciones para cada pareja \"Origin\", \"Dest\" (una agregación para el retraso medio y otra para contar), aplica el método sort(F.col(\"avgDelay\").desc()) para ordenar de forma decreciente por la nueva columna del retraso medio.\n",
    "</div>\n",
    "\n",
    "**Nota:** vamos a practicar con la función `F.round(columna, cifras_decimales)` que recibe un objeto columna numérica y el número de cifras decimales a las que queremos redondearlo, y devuelve otro objeto columna numérico redondeado. OJO: el nuevo objeto columna devuelto no conserva el nombre que tenía el objeto original, sino que trae el nombre por defecto \"round(col_original, n_cifras)\" así que conviene renombrarlo con `alias()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:=============================>                             (2 + 2) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+---------+---+\n",
      "|Origin|Dest|meanDelay|  n|\n",
      "+------+----+---------+---+\n",
      "|   RDM| MFR|   1347.0|  2|\n",
      "|   MDT| HPN|    798.0|  1|\n",
      "|   ORD| GTF|    212.0|  1|\n",
      "|   ICT| DAY|    210.0|  1|\n",
      "|   ELM| ATL|    169.0|  2|\n",
      "|   DSM| PIA|    168.0|  1|\n",
      "|   ERI| ITH|    160.0|  1|\n",
      "|   YNG| PIE|    141.0|  1|\n",
      "|   CMH| HOU|    120.0|  1|\n",
      "|   HRL| DAL|    111.0|  1|\n",
      "|   PPG| HNL|  109.857| 35|\n",
      "|   HNL| PPG|  105.857| 35|\n",
      "|   PIE| YNG|    104.0|  1|\n",
      "|   AVP| SFB|     93.0|  1|\n",
      "|   ACY| MSY|   87.455| 11|\n",
      "|   CPR| LAS|     85.0|  1|\n",
      "|   LAS| CPR|     82.0|  1|\n",
      "|   TTN| BNA|     76.5| 10|\n",
      "|   MSP| PVD|     74.0|  1|\n",
      "|   TUL| OKC|     69.0|  1|\n",
      "+------+----+---------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "averageDelayOriginDest = cleanFlightsDF.groupBy(\"Origin\", \"Dest\")\\\n",
    "                                       .agg(F.round(F.mean(\"ArrDelay\"), 3).alias(\"meanDelay\"),\n",
    "                                            F.count(\"*\").alias(\"n\")\n",
    "                                           )\\\n",
    "                                       .orderBy(\"meanDelay\", ascending=False)\n",
    "averageDelayOriginDest.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <p><b>PREGUNTA</b>: ¿Es el avión un medio de transporte fiable?</p>\n",
    "    <p>(a) Mostrar, para cada aeropuerto de destino, el número de vuelos que hay en cada <i>categoría de retraso</i> (variable ArrDelayCat). En lugar de llamar agg(F.count(\"*\")), podemos llamar a la transformación count() sobre el resultado de groupBy(), y creará automáticamente una columna llamada \"count\" con los conteos para cada grupo. Guardarlo en la variable arr_delay_cat_df.\n",
    "<p> (b) Ahora agrupa por cada aeropuerto de origen y de destino, y mostrando una columna distinta por cada tipo de retraso, con el recuento del número de vuelos en cada combinación. Guardarlo en la variable arr_delay_cat_pivot_df. PISTA: utilizar la función pivot(\"colName\").</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:===================>                                       (1 + 2) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------+-----+\n",
      "|Dest|ArrDelayCat|count|\n",
      "+----+-----------+-----+\n",
      "| SRQ|       Huge|  123|\n",
      "| OMA|     Slight| 1030|\n",
      "| LRD|       None|  664|\n",
      "| CIU|       None|  163|\n",
      "| BGR|       Huge|  247|\n",
      "| BPT|       Huge|   28|\n",
      "| PPG|       None|   23|\n",
      "| MMH|       None|  239|\n",
      "| FNT|       Huge|  154|\n",
      "| COU|       Huge|  100|\n",
      "| SRQ|       None| 1789|\n",
      "| ISN|       None|  448|\n",
      "| DBQ|       Huge|   36|\n",
      "| TXK|       None|  269|\n",
      "| ASE|       None| 2424|\n",
      "| ABI|     Slight|   87|\n",
      "| TOL|       None|  559|\n",
      "| FAT|       Huge|  202|\n",
      "| ROC|     Slight|  780|\n",
      "| IAG|     Slight|   26|\n",
      "+----+-----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "array_delay_cat_df = cleanFlightsDF\\\n",
    "    .groupBy('Dest','ArrDelayCat')\\\n",
    "    .count()\n",
    "\n",
    "array_delay_cat_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 10:===========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+------+----+----+\n",
      "|Origin|Dest|Slight|None|Huge|\n",
      "+------+----+------+----+----+\n",
      "|   LBB| DEN|    20| 184|  20|\n",
      "|   TPA| ACY|     4| 112|   4|\n",
      "|   PHL| MCO|   273|1291| 162|\n",
      "|   ORD| PDX|    85| 528|  23|\n",
      "|   SNA| PHX|   256| 967|  57|\n",
      "|   MDW| MEM|    42| 172|  22|\n",
      "|   DSM| EWR|    14|  94|  10|\n",
      "|   SPI| ORD|    37| 255|  50|\n",
      "|   FSD| ATL|     9|  83|   9|\n",
      "|   MCI| IAH|    54| 487|  38|\n",
      "|   SJC| LIH|     5|  83|   1|\n",
      "|   DSM| MCO|    10|  30|   1|\n",
      "|   LAS| LIT|    22|  93|   5|\n",
      "|   PBG| PGD|     6|  19|   1|\n",
      "|   SHD| LWB|  null|  25|   2|\n",
      "|   IAD| ILM|     8|  34|   2|\n",
      "|   EWR| STT|  null|   4|null|\n",
      "|   CPR| DEN|    55| 330|  51|\n",
      "|   CVG| BDL|    11|  78|   5|\n",
      "|   ICT| IAH|    37| 375|  37|\n",
      "+------+----+------+----+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "array_delay_cat_pivot_df = cleanFlightsDF\\\n",
    "    .groupBy('Origin','Dest')\\\n",
    "    .pivot('ArrDelayCat', [\"Slight\", \"None\", \"Huge\"])\\\n",
    "    .count()\n",
    "\n",
    "array_delay_cat_pivot_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<p><b>PREGUNTA</b>: ¿Hay relación entre el día de la semana y el retraso a la salida o a la llegada?</p>\n",
    "    <p> (a) Sin usar la función pivot, calcula el retraso medio a la salida y a la llegada para cada día de la semana y ordena por una de ellas descendentemente.</p>\n",
    "    <p> (b) Ahora haz lo mismo para cada día pero calculando solamente el retraso medio a la llegada, desagregado por cada aeropuerto de origen y destino, utilizando la función pivot() para generar un DF con tantas columnas como días de la semana, más dos (el origen y destino). </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<p><b>LA FUNCIÓN PIVOT</b>: Puede ser interesante ver, para cada (Origin, Dest), el retraso promedio por\n",
    "día de la semana. Si agrupamos por esas tres variables (Origin, Dest, DayOfWeek), nuestro resultado tendría demasiadas filas para ser fácil de visualizar (7 x 1009 ya que hay 1009 combinaciones de (Origin, DayOfWeek)). En cambio, vamos a crear 7 columnas, una por día de la semana, en nuestro resultado DF. Lo haremos utilizando una de las variables de agrupación (DayOfWeek) como <i> variable pivot</i>. Como esta variable tiene 7 valores distintos, se crearán 7 columnas nuevas. De esta manera, visualizaremos toda la información de cada combinación (Origen, Dest) condensada en una fila con 7 columnas con los 7 retrasos promedio correspondientes a ese (Origen, Dest) en cada día de la semana.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 14:======================================>                   (2 + 1) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+---------+------------------+---------+\n",
      "|Origin|Dest|DayOfWeek|       AvgArrDelay|groupSize|\n",
      "+------+----+---------+------------------+---------+\n",
      "|   RDM| MFR|        7|            1347.0|        2|\n",
      "|   MDT| HPN|        5|             798.0|        1|\n",
      "|   RSW| TTN|        2|             393.0|        1|\n",
      "|   GRK| ATL|        3|             392.5|        2|\n",
      "|   IND| AZA|        6|             382.0|        1|\n",
      "|   SJU| SFB|        3|             360.0|        1|\n",
      "|   SFB| SJU|        3|             357.0|        1|\n",
      "|   ELM| ATL|        2|             346.0|        1|\n",
      "|   HNL| IAD|        5|243.33333333333334|        6|\n",
      "|   PPG| HNL|        5|238.45454545454547|       11|\n",
      "|   HNL| PPG|        5|238.36363636363637|       11|\n",
      "|   FCA| ORD|        2|             224.0|        1|\n",
      "|   OAK| DFW|        2|223.33333333333334|        6|\n",
      "|   BLV| JAX|        2|             213.0|        1|\n",
      "|   ORD| GTF|        1|             212.0|        1|\n",
      "|   ICT| DAY|        2|             210.0|        1|\n",
      "|   PSC| LAS|        2|             210.0|        1|\n",
      "|   ORD| FCA|        2|             205.0|        1|\n",
      "|   JAX| BLV|        2|             203.0|        1|\n",
      "|   MYR| CMH|        6|192.16666666666666|        6|\n",
      "+------+----+---------+------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "ej4a = cleanFlightsDF.groupBy('Origin','Dest', 'DayOfWeek')\\\n",
    "                     .agg(\n",
    "                          F.mean(\"ArrDelay\").alias(\"AvgArrDelay\"),\n",
    "                          F.count(\"*\").alias(\"groupSize\")\n",
    "                     )\\\n",
    "                     .sort(F.col('AvgArrDelay').desc())\n",
    "\n",
    "ej4a.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 25:===========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+--------------------+--------------------+-------------------+-------------------+-------------------+-------------------+--------------------+\n",
      "|Origin|Dest|                   1|                   2|                  3|                  4|                  5|                  6|                   7|\n",
      "+------+----+--------------------+--------------------+-------------------+-------------------+-------------------+-------------------+--------------------+\n",
      "|   LBB| DEN|  12.057142857142857| -1.9393939393939394|  4.454545454545454|-11.294117647058824| 27.558823529411764|  7.413793103448276| -4.2272727272727275|\n",
      "|   TPA| ACY|  -6.647058823529412|  -4.529411764705882|-3.6470588235294117|           -12.5625|            -11.125|-10.588235294117647|  -6.235294117647059|\n",
      "|   MCI| IAH|               -4.75|-0.17721518987341772|  1.654320987654321| 11.607142857142858| -8.047619047619047|-10.486486486486486| -1.1168831168831168|\n",
      "|   DSM| MCO|                null|   9.428571428571429|               null|  5.214285714285714|               null|               null|   13.76923076923077|\n",
      "|   LAS| LIT|   6.944444444444445|   16.11764705882353| 3.3529411764705883|            -0.3125| 23.294117647058822| -5.823529411764706|  -7.470588235294118|\n",
      "|   SJC| LIH|              -4.875|  -22.11764705882353| 21.833333333333332|-15.647058823529411|-10.142857142857142|-12.529411764705882| -11.235294117647058|\n",
      "|   MDW| MEM|   7.705882352941177|   6.235294117647059| 1.0909090909090908|-1.1612903225806452|           -1.09375|               -4.5|  15.310344827586206|\n",
      "|   ORD| PDX|               -1.59| -1.5909090909090908|  1.064516129032258| 3.6451612903225805| 2.2934782608695654| -6.595505617977528|  1.9367088607594938|\n",
      "|   BQN| MCO|   17.11111111111111|  11.176470588235293|  8.823529411764707| -1.411764705882353| -5.823529411764706|            -3.3125|                13.0|\n",
      "|   STS| PHX|               -1.15|   67.11111111111111| 0.7777777777777778|-0.2777777777777778| 13.777777777777779| -1.588235294117647|  11.166666666666666|\n",
      "|   PBG| PGD|                null|               -3.75|               null|  41.18181818181818|               null|               null|-0.36363636363636365|\n",
      "|   ATL| GSP|-0.03108808290155...|  -4.869565217391305|0.37362637362637363|-2.0053763440860215|0.40641711229946526|  -5.89922480620155| -1.4242424242424243|\n",
      "|   PHL| MCO|          8.48046875|  13.991228070175438|  7.927272727272728|-0.8798283261802575|  7.890295358649789|   6.22007722007722|   9.099601593625499|\n",
      "|   SNA| PHX|   6.780487804878049|  7.1861702127659575|  5.348958333333333|  9.133333333333333|  8.954081632653061|-1.7804878048780488|   6.702247191011236|\n",
      "|   PBI| DCA|  3.3043478260869565|   2.803030303030303|            4.21875|               -7.4|-1.0491803278688525| -8.941176470588236|  3.8266666666666667|\n",
      "|   DSM| EWR|   7.529411764705882|  -5.294117647058823| -8.214285714285714|-0.5333333333333333|            -3.6875|  8.588235294117647|  -6.647058823529412|\n",
      "|   SMF| BUR|  11.234899328859061|   4.680851063829787| 5.4411764705882355| 11.460992907801419|  8.986013986013987| -3.289473684210526|   5.153846153846154|\n",
      "|   SPI| ORD|               31.98|  33.816326530612244|  3.450980392156863|               4.72|-1.5416666666666667|  9.735294117647058|  25.416666666666668|\n",
      "|   MCI| MKE| -2.7714285714285714| -2.4411764705882355| -3.323529411764706| 0.7272727272727273| -4.705882352941177|               -7.4|   6.285714285714286|\n",
      "|   IAD| ILM|                 8.0|                 5.5| 1.1666666666666667|  7.333333333333333|-2.1666666666666665| 26.666666666666668|                 4.0|\n",
      "+------+----+--------------------+--------------------+-------------------+-------------------+-------------------+-------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "ej4b = cleanFlightsDF.groupBy('Origin','Dest')\\\n",
    "               .pivot(\"DayOfWeek\")\\\n",
    "               .agg(\n",
    "                    F.mean(\"ArrDelay\").alias(\"AvgArrDelay\")  # este alias será ignorado\n",
    "                )\n",
    "ej4b.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operaciones JOIN y de ventana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estaría bien tener el retraso promedio de una ruta junto a cada vuelo, para que podamos ver qué vuelos tuvieron un retraso que fue superior o inferior al retraso promedio de esa ruta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b> PREGUNTA </b>:\n",
    "Usa el averageDelayOriginDestDF creado anteriormente, elimina la columna de conteo y luego únerlo con cleanFlightsDF, utilizando Origin y Dest como columnas de enlace. Finalmente, selecciona solo las columnas Origin, Dest, DayOfWeek, ArrDelay y avgDelay del resultado.\n",
    "</div>\n",
    "\n",
    "**PREGUNTA**: ¿qué tipo de JOIN utilizarías? ¿Es relevante en este caso?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/05/02 09:21:08 WARN org.apache.spark.sql.catalyst.util.package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+-----+----------+---------+----------+--------------------+--------------+-------+--------+-------+--------+---------+----------------+--------+-----------------+-------+--------+------------+------------+--------+-------------+-----------------+-----------+---------+---+\n",
      "|Origin|Dest|Month|DayofMonth|DayOfWeek|FlightDate|          OriginCity|      DestCity|DepTime|DepDelay|ArrTime|ArrDelay|Cancelled|CancellationCode|Diverted|ActualElapsedTime|AirTime|Distance|CarrierDelay|WeatherDelay|NASDelay|SecurityDelay|LateAircraftDelay|ArrDelayCat|meanDelay|  n|\n",
      "+------+----+-----+----------+---------+----------+--------------------+--------------+-------+--------+-------+--------+---------+----------------+--------+-----------------+-------+--------+------------+------------+--------+-------------+-----------------+-----------+---------+---+\n",
      "|   BQN| MCO|    1|         1|        1|2018-01-01|       Aguadilla, PR|   Orlando, FL|    412|    -2.0|    618|     9.0|      0.0|            null|     0.0|            186.0|  158.0|  1129.0|        null|        null|    null|         null|             null|       None|    5.763|119|\n",
      "|   PBI| DCA|    1|         1|        1|2018-01-01|West Palm Beach/P...|Washington, DC|   1522|    62.0|   1727|    48.0|      0.0|            null|     0.0|            125.0|  110.0|   857.0|         0.0|         0.0|    22.0|          0.0|             26.0|     Slight|   -0.391|479|\n",
      "|   PBI| DCA|    1|         1|        1|2018-01-01|West Palm Beach/P...|Washington, DC|   1138|     3.0|   1345|    -6.0|      0.0|            null|     0.0|            127.0|  110.0|   857.0|        null|        null|    null|         null|             null|       None|   -0.391|479|\n",
      "|   PBI| DCA|    1|         1|        1|2018-01-01|West Palm Beach/P...|Washington, DC|   1956|    72.0|   2204|    64.0|      0.0|            null|     0.0|            128.0|  109.0|   857.0|        64.0|         0.0|     0.0|          0.0|              0.0|       Huge|   -0.391|479|\n",
      "|   BQN| MCO|    1|         2|        2|2018-01-02|       Aguadilla, PR|   Orlando, FL|    528|    74.0|    716|    67.0|      0.0|            null|     0.0|            168.0|  147.0|  1129.0|         0.0|         0.0|     0.0|          0.0|             67.0|       Huge|    5.763|119|\n",
      "|   PBI| DCA|    1|         2|        2|2018-01-02|West Palm Beach/P...|Washington, DC|   1409|    -2.0|   1629|    -1.0|      0.0|            null|     0.0|            140.0|  108.0|   857.0|        null|        null|    null|         null|             null|       None|   -0.391|479|\n",
      "|   PBI| DCA|    1|         2|        2|2018-01-02|West Palm Beach/P...|Washington, DC|   1202|    27.0|   1424|    33.0|      0.0|            null|     0.0|            142.0|  109.0|   857.0|        11.0|         0.0|     6.0|          0.0|             16.0|     Slight|   -0.391|479|\n",
      "|   PBI| DCA|    1|         2|        2|2018-01-02|West Palm Beach/P...|Washington, DC|   1837|    -7.0|   2038|   -22.0|      0.0|            null|     0.0|            121.0|  106.0|   857.0|        null|        null|    null|         null|             null|       None|   -0.391|479|\n",
      "|   BQN| MCO|    1|         3|        3|2018-01-03|       Aguadilla, PR|   Orlando, FL|    438|    24.0|    638|    29.0|      0.0|            null|     0.0|            180.0|  154.0|  1129.0|         6.0|         0.0|     5.0|          0.0|             18.0|     Slight|    5.763|119|\n",
      "|   PBI| DCA|    1|         3|        3|2018-01-03|West Palm Beach/P...|Washington, DC|   1421|    10.0|   1641|    11.0|      0.0|            null|     0.0|            140.0|  109.0|   857.0|        null|        null|    null|         null|             null|       None|   -0.391|479|\n",
      "|   PBI| DCA|    1|         3|        3|2018-01-03|West Palm Beach/P...|Washington, DC|   1735|   360.0|   1953|   362.0|      0.0|            null|     0.0|            138.0|  113.0|   857.0|       360.0|         0.0|     2.0|          0.0|              0.0|       Huge|   -0.391|479|\n",
      "|   PBI| DCA|    1|         3|        3|2018-01-03|West Palm Beach/P...|Washington, DC|   1935|    51.0|   2143|    43.0|      0.0|            null|     0.0|            128.0|  113.0|   857.0|         9.0|         0.0|     0.0|          0.0|             34.0|     Slight|   -0.391|479|\n",
      "|   BQN| MCO|    1|         4|        4|2018-01-04|       Aguadilla, PR|   Orlando, FL|    254|    22.0|    446|    19.0|      0.0|            null|     0.0|            172.0|  157.0|  1129.0|         0.0|         0.0|     0.0|          0.0|             19.0|     Slight|    5.763|119|\n",
      "|   PBI| DCA|    1|         4|        4|2018-01-04|West Palm Beach/P...|Washington, DC|   1252|    -5.0|   1504|   -12.0|      0.0|            null|     0.0|            132.0|  115.0|   857.0|        null|        null|    null|         null|             null|       None|   -0.391|479|\n",
      "|   BQN| MCO|    1|         5|        5|2018-01-05|       Aguadilla, PR|   Orlando, FL|    229|    -9.0|    419|   -14.0|      0.0|            null|     0.0|            170.0|  153.0|  1129.0|        null|        null|    null|         null|             null|       None|    5.763|119|\n",
      "|   BQN| MCO|    1|        22|        1|2018-01-22|       Aguadilla, PR|   Orlando, FL|    228|   -10.0|    410|   -23.0|      0.0|            null|     0.0|            162.0|  147.0|  1129.0|        null|        null|    null|         null|             null|       None|    5.763|119|\n",
      "|   PBI| DCA|    1|        22|        1|2018-01-22|West Palm Beach/P...|Washington, DC|   1247|   -10.0|   1452|   -24.0|      0.0|            null|     0.0|            125.0|  113.0|   857.0|        null|        null|    null|         null|             null|       None|   -0.391|479|\n",
      "|   BQN| MCO|    1|        23|        2|2018-01-23|       Aguadilla, PR|   Orlando, FL|    246|     8.0|    430|    -3.0|      0.0|            null|     0.0|            164.0|  148.0|  1129.0|        null|        null|    null|         null|             null|       None|    5.763|119|\n",
      "|   PBI| DCA|    1|        23|        2|2018-01-23|West Palm Beach/P...|Washington, DC|   1257|     0.0|   1457|   -19.0|      0.0|            null|     0.0|            120.0|  106.0|   857.0|        null|        null|    null|         null|             null|       None|   -0.391|479|\n",
      "|   BQN| MCO|    1|        24|        3|2018-01-24|       Aguadilla, PR|   Orlando, FL|    249|    11.0|    421|   -12.0|      0.0|            null|     0.0|            152.0|  139.0|  1129.0|        null|        null|    null|         null|             null|       None|    5.763|119|\n",
      "+------+----+-----+----------+---------+----------+--------------------+--------------+-------+--------+-------+--------+---------+----------------+--------+-----------------+-------+--------+------------+------------+--------+-------------+-----------------+-----------+---------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joinedDF = cleanFlightsDF.join(averageDelayOriginDest, on = [\"Origin\", \"Dest\"], how = \"left_outer\")\n",
    "\n",
    "# podríamos usar inner también! En este caso da igual, porque todas las combinaciones de Origin y Dest que existan en\n",
    "# cleanFlightsDF sabemos con seguridad que también existirán en averageDelayOriginDest, ya que este proviene de cleanFlightsDF\n",
    "\n",
    "joinedDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p><b>BONUS (OPCIONAL)</b>: crear una nueva columna <i>belowAverage</i> que tenga valor True si ArrDelay es menor que el avgDelay de esa ruta, y False en caso contrario. No utilizar la función when() sino el operador de comparación directamente entre columnas, la cual devolverá una columna booleana.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+----------+--------+---------+------------+\n",
      "|Origin|Dest|FlightDate|ArrDelay|MeanDelay|belowAverage|\n",
      "+------+----+----------+--------+---------+------------+\n",
      "|   BQN| MCO|2018-01-01|     9.0|    5.763|       false|\n",
      "|   PBI| DCA|2018-01-01|    48.0|   -0.391|       false|\n",
      "|   PBI| DCA|2018-01-01|    -6.0|   -0.391|        true|\n",
      "|   PBI| DCA|2018-01-01|    64.0|   -0.391|       false|\n",
      "|   BQN| MCO|2018-01-02|    67.0|    5.763|       false|\n",
      "|   PBI| DCA|2018-01-02|    -1.0|   -0.391|        true|\n",
      "|   PBI| DCA|2018-01-02|    33.0|   -0.391|       false|\n",
      "|   PBI| DCA|2018-01-02|   -22.0|   -0.391|        true|\n",
      "|   BQN| MCO|2018-01-03|    29.0|    5.763|       false|\n",
      "|   PBI| DCA|2018-01-03|    11.0|   -0.391|       false|\n",
      "|   PBI| DCA|2018-01-03|   362.0|   -0.391|       false|\n",
      "|   PBI| DCA|2018-01-03|    43.0|   -0.391|       false|\n",
      "|   BQN| MCO|2018-01-04|    19.0|    5.763|       false|\n",
      "|   PBI| DCA|2018-01-04|   -12.0|   -0.391|        true|\n",
      "|   BQN| MCO|2018-01-05|   -14.0|    5.763|        true|\n",
      "|   BQN| MCO|2018-01-22|   -23.0|    5.763|        true|\n",
      "|   PBI| DCA|2018-01-22|   -24.0|   -0.391|        true|\n",
      "|   BQN| MCO|2018-01-23|    -3.0|    5.763|        true|\n",
      "|   PBI| DCA|2018-01-23|   -19.0|   -0.391|        true|\n",
      "|   BQN| MCO|2018-01-24|   -12.0|    5.763|        true|\n",
      "+------+----+----------+--------+---------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Al final seleccionamos solo algunas columnas para mostrar el resultado sin que sea demasiado ancho\n",
    "ej5 = joinedDF.withColumn('belowAverage', F.col('ArrDelay') < F.col('MeanDelay'))\\\n",
    "              .select(\"Origin\", \"Dest\", \"FlightDate\", \"ArrDelay\", \"MeanDelay\", \"belowAverage\") \n",
    "\n",
    "ej5.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b> PREGUNTA </b>:repetir la operación utilizando funciones de ventana, sin usar `join`.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 43:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+----------+--------+-----------------+\n",
      "|Origin|Dest|FlightDate|ArrDelay|MeanDelay        |\n",
      "+------+----+----------+--------+-----------------+\n",
      "|ABE   |CLT |2018-02-01|36.0    |5.876494023904383|\n",
      "|ABE   |CLT |2018-02-02|-14.0   |5.876494023904383|\n",
      "|ABE   |CLT |2018-02-03|9.0     |5.876494023904383|\n",
      "|ABE   |CLT |2018-02-04|347.0   |5.876494023904383|\n",
      "|ABE   |CLT |2018-02-05|0.0     |5.876494023904383|\n",
      "|ABE   |CLT |2018-02-06|2.0     |5.876494023904383|\n",
      "|ABE   |CLT |2018-02-07|12.0    |5.876494023904383|\n",
      "|ABE   |CLT |2018-02-08|12.0    |5.876494023904383|\n",
      "|ABE   |CLT |2018-02-09|-7.0    |5.876494023904383|\n",
      "|ABE   |CLT |2018-02-10|46.0    |5.876494023904383|\n",
      "|ABE   |CLT |2018-02-11|null    |5.876494023904383|\n",
      "|ABE   |CLT |2018-02-12|4.0     |5.876494023904383|\n",
      "|ABE   |CLT |2018-02-13|31.0    |5.876494023904383|\n",
      "|ABE   |CLT |2018-02-14|-17.0   |5.876494023904383|\n",
      "|ABE   |CLT |2018-02-15|19.0    |5.876494023904383|\n",
      "|ABE   |CLT |2018-02-16|11.0    |5.876494023904383|\n",
      "|ABE   |CLT |2018-02-17|93.0    |5.876494023904383|\n",
      "|ABE   |CLT |2018-02-18|-3.0    |5.876494023904383|\n",
      "|ABE   |CLT |2018-02-19|1.0     |5.876494023904383|\n",
      "|ABE   |CLT |2018-02-20|8.0     |5.876494023904383|\n",
      "+------+----+----------+--------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Window\n",
    "\n",
    "w = Window().partitionBy([\"Origin\",\"Dest\"])\n",
    "flightsWindowDF = flightsDF\\\n",
    "                    .withColumn(\"MeanDelay\", F.mean(\"ArrDelay\").over(w))\\\n",
    "                    .withColumn(\"belowAverage\", F.col(\"ArrDelay\") < F.col(\"MeanDelay\"))\\\n",
    "                    .select(\"Origin\", \"Dest\", \"FlightDate\", \"ArrDelay\", \"MeanDelay\")\\\n",
    "\n",
    "flightsWindowDF.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones de agregación para traer, en cada grupo, todos los valores de cierta columna que hay en ese grupo. Esto genera una columna de tipo lista o de tipo conjunto\n",
    "\n",
    "#### Funciones F.collect_list() y F.collect_set(), que pueden utilizarse dentro de agg() en groupBy().agg() y también en una ventana, como ocurre con cualquier función de agregación\n",
    "\n",
    "#### Funciones para manejar columnas de tipo vector: todas las que empiezan por array_ [aquí](https://spark.apache.org/docs/3.1.3/api/python/reference/pyspark.sql.html#functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 44:===========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------+\n",
      "|Origin|Dest|fechas_sin_repetidos                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |primer_elemento|\n",
      "+------+----+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------+\n",
      "|ABE   |CLT |[2018-01-29, 2018-02-02, 2018-02-04, 2018-01-10, 2018-01-08, 2018-01-02, 2018-01-13, 2018-03-27, 2018-03-07, 2018-03-24, 2018-01-23, 2018-02-27, 2018-02-17, 2018-01-18, 2018-04-09, 2018-01-20, 2018-03-10, 2018-01-12, 2018-04-08, 2018-02-01, 2018-04-26, 2018-03-09, 2018-03-26, 2018-04-03, 2018-03-04, 2018-04-14, 2018-03-14, 2018-02-22, 2018-01-24, 2018-01-30, 2018-04-13, 2018-04-22, 2018-01-16, 2018-01-26, 2018-03-08, 2018-03-21, 2018-02-24, 2018-04-19, 2018-04-01, 2018-04-06, 2018-01-03, 2018-04-15, 2018-04-24, 2018-04-02, 2018-03-06, 2018-03-30, 2018-02-21, 2018-02-23, 2018-03-23, 2018-03-29, 2018-02-08, 2018-02-16, 2018-04-04, 2018-02-03, 2018-02-10, 2018-02-09, 2018-03-19, 2018-04-20, 2018-03-12, 2018-01-27, 2018-03-15, 2018-04-25, 2018-02-14, 2018-01-25, 2018-02-06, 2018-02-18, 2018-03-25, 2018-04-16, 2018-02-19, 2018-03-16, 2018-01-22, 2018-01-17, 2018-04-17, 2018-02-11, 2018-04-21, 2018-02-07, 2018-03-17, 2018-03-31, 2018-02-25, 2018-01-19, 2018-01-07, 2018-01-09, 2018-01-21, 2018-03-22, 2018-04-27, 2018-04-30, 2018-03-18, 2018-04-05, 2018-04-11, 2018-03-02, 2018-01-14, 2018-01-05, 2018-01-06, 2018-04-10, 2018-03-05, 2018-02-28, 2018-02-20, 2018-03-13, 2018-04-23, 2018-02-15, 2018-01-01, 2018-04-07, 2018-04-28, 2018-04-18, 2018-02-05, 2018-02-13, 2018-01-28, 2018-04-29, 2018-01-11, 2018-01-15, 2018-02-12, 2018-01-31, 2018-02-26, 2018-03-01, 2018-04-12, 2018-03-03, 2018-03-11, 2018-03-28, 2018-01-04, 2018-03-20]|2018-01-01     |\n",
      "|ABE   |FLL |[2018-01-06, 2018-01-27, 2018-02-28, 2018-04-25, 2018-02-14, 2018-01-10, 2018-04-14, 2018-03-14, 2018-04-07, 2018-01-13, 2018-04-28, 2018-01-24, 2018-04-18, 2018-03-21, 2018-03-07, 2018-03-24, 2018-02-24, 2018-01-17, 2018-01-03, 2018-04-21, 2018-02-07, 2018-03-17, 2018-03-31, 2018-02-17, 2018-01-31, 2018-02-21, 2018-01-20, 2018-03-03, 2018-03-10, 2018-03-28, 2018-04-04, 2018-04-11, 2018-02-03, 2018-02-10]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |2018-02-03     |\n",
      "|ABI   |DFW |[2018-01-29, 2018-02-02, 2018-02-04, 2018-01-10, 2018-01-08, 2018-01-02, 2018-01-13, 2018-03-27, 2018-03-07, 2018-03-24, 2018-01-23, 2018-02-27, 2018-02-17, 2018-01-18, 2018-04-09, 2018-01-20, 2018-03-10, 2018-01-12, 2018-04-08, 2018-02-01, 2018-04-26, 2018-03-09, 2018-03-26, 2018-04-03, 2018-03-04, 2018-04-14, 2018-03-14, 2018-02-22, 2018-01-24, 2018-01-30, 2018-04-13, 2018-04-22, 2018-01-16, 2018-01-26, 2018-03-21, 2018-03-08, 2018-02-24, 2018-04-19, 2018-04-01, 2018-04-06, 2018-01-03, 2018-04-15, 2018-04-24, 2018-04-02, 2018-03-06, 2018-03-30, 2018-02-21, 2018-02-23, 2018-03-23, 2018-04-04, 2018-02-08, 2018-02-16, 2018-03-29, 2018-02-03, 2018-02-10, 2018-02-09, 2018-03-19, 2018-04-20, 2018-03-12, 2018-01-27, 2018-03-15, 2018-04-25, 2018-02-14, 2018-01-25, 2018-02-18, 2018-02-06, 2018-03-25, 2018-04-16, 2018-02-19, 2018-03-16, 2018-01-22, 2018-01-17, 2018-04-17, 2018-02-11, 2018-04-21, 2018-02-07, 2018-03-17, 2018-03-31, 2018-02-25, 2018-01-19, 2018-01-07, 2018-01-09, 2018-01-21, 2018-03-22, 2018-04-27, 2018-04-30, 2018-03-18, 2018-04-05, 2018-04-11, 2018-03-02, 2018-01-14, 2018-01-05, 2018-01-06, 2018-04-10, 2018-03-05, 2018-02-28, 2018-02-20, 2018-03-13, 2018-04-23, 2018-02-15, 2018-01-01, 2018-04-07, 2018-04-28, 2018-04-18, 2018-02-05, 2018-02-13, 2018-01-28, 2018-04-29, 2018-01-11, 2018-01-15, 2018-02-12, 2018-01-31, 2018-02-26, 2018-03-01, 2018-04-12, 2018-03-03, 2018-03-11, 2018-03-28, 2018-01-04, 2018-03-20]|2018-01-01     |\n",
      "+------+----+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "todasFechasDF = flightsDF.groupBy(\"Origin\", \"Dest\")\\\n",
    "                    .agg(F.collect_list(\"FlightDate\").alias(\"todas_fechas\"),\n",
    "                         F.collect_set(\"FlightDate\").alias(\"fechas_sin_repetidos\")\n",
    "                    )\\\n",
    "                    .withColumn(\"primer_elemento\", F.element_at(\"todas_fechas\", 1)) # primer elemento de cada array\n",
    "\n",
    "# mostramos 3 filas y solo algunas columnas para que no sea muy largo\n",
    "todasFechasDF.select(\"Origin\", \"Dest\", \"fechas_sin_repetidos\", \"primer_elemento\").show(3, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones para crear una columna de tipo estructura\n",
    "\n",
    "Una columna de tipo estructura representa un tipo de dato creado por el usuario, que puede ser \"plano\", es decir, ser simplemente una tupla, o puede ser \"jerárquico\" porque dentro de la estructura existan campos que son, a su vez, otras estructuras. El caso más simple es crear una tupla con los valores de varias columnas, fila a fila. Es posible \"ordenar\" tuplas, porque ordena en base al primer elemento de cada tupla (el más a la izquierda), y si empatan entonces se fija en el segundo, y así sucesivamente.\n",
    "\n",
    "Esto es útil cuando queremos ordenar dentro de un grupo en base a cierta columna, y después queremos ver el valor concreto de otra columna diferente que estaba en la misma fila, emparejado con el valor máximo o mínimo (es decir, cuando buscamos máximo o mínimo pero *no queremos perder la correspondencia* de ese valor con otros valores de su fila).\n",
    "\n",
    "Se puede acceder a cada uno de los campos de una tupla con el operador `.` (punto)\n",
    "\n",
    "**Ejemplo**: para cada par de aeropuertos origen y destino, encontrar la fecha en la que tuvo lugar el vuelo con más retraso a la llegada. Como estamos creando una columna de tipo estructura con dos campos, de los cuales el primero es el ArrDelay, al buscar dentro de cada grupo el máximo de dicha columna de tipo estructura, se fijará justamente en el ArrDelay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 47:===========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+--------------------+-----------------+\n",
      "|Origin|Dest|max_struct          |fecha_max_retraso|\n",
      "+------+----+--------------------+-----------------+\n",
      "|ABE   |CLT |{347.0, 2018-02-04} |2018-02-04       |\n",
      "|ABE   |FLL |{340.0, 2018-03-07} |2018-03-07       |\n",
      "|ABI   |DFW |{397.0, 2018-01-01} |2018-01-01       |\n",
      "|ABQ   |ORD |{460.0, 2018-04-16} |2018-04-16       |\n",
      "|ABY   |ATL |{641.0, 2018-01-07} |2018-01-07       |\n",
      "|ACY   |FLL |{1385.0, 2018-04-05}|2018-04-05       |\n",
      "|ACY   |MCO |{296.0, 2018-04-27} |2018-04-27       |\n",
      "|ACY   |MYR |{352.0, 2018-04-21} |2018-04-21       |\n",
      "|ACY   |PBI |{132.0, 2018-02-10} |2018-02-10       |\n",
      "|ADQ   |ANC |{221.0, 2018-03-20} |2018-03-20       |\n",
      "|AEX   |DFW |{467.0, 2018-02-22} |2018-02-22       |\n",
      "|AGS   |ATL |{1366.0, 2018-01-23}|2018-01-23       |\n",
      "|AGS   |DFW |{80.0, 2018-04-03}  |2018-04-03       |\n",
      "|AGS   |PHL |{215.0, 2018-04-04} |2018-04-04       |\n",
      "|ALB   |EWR |{390.0, 2018-02-05} |2018-02-05       |\n",
      "|ALB   |MSP |{131.0, 2018-03-29} |2018-03-29       |\n",
      "|ALO   |ORD |{435.0, 2018-04-17} |2018-04-17       |\n",
      "|ALW   |SEA |{175.0, 2018-04-10} |2018-04-10       |\n",
      "|AMA   |DAL |{274.0, 2018-02-20} |2018-02-20       |\n",
      "|AMA   |DEN |{281.0, 2018-02-08} |2018-02-08       |\n",
      "+------+----+--------------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Window\n",
    "\n",
    "fechaMaxDelayDF = flightsDF\\\n",
    "                    .withColumn(\"estructura\", F.struct(\"ArrDelay\", \"FlightDate\"))\\\n",
    "                    .groupBy(\"Origin\", \"Dest\")\\\n",
    "                    .agg(F.max(\"estructura\").alias(\"max_struct\"))\\\n",
    "                    .withColumn(\"fecha_max_retraso\", F.col(\"max_struct.FlightDate\"))\n",
    "\n",
    "fechaMaxDelayDF.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b> PREGUNTA </b>: Vamos a construir otro DF con información sobre los aeropuertos (en una situación real, tendríamos otra tabla en la base de datos como la tabla de la entidad Aeropuerto). Sin embargo, solo tenemos información sobre algunos aeropuertos. Nos gustaría agregar esta información a cleanFlightsDF como nuevas columnas, teniendo en cuenta que queremos que la información del aeropuerto coincida con el aeropuerto de origen de flightsDF. Utilizar la operación de unión adecuada para asegurarse de que no se perderá ninguna de las filas existentes de cleanFlightsDF después de la unión.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 51:===================>                                      (1 + 2) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------------------------------+----+\n",
      "|IATA|FullName                             |Year|\n",
      "+----+-------------------------------------+----+\n",
      "|JFK |John F. Kennedy International Airport|1948|\n",
      "|LIT |Little Rock National Airport         |1931|\n",
      "|SEA |Seattle-Tacoma International Airport |1949|\n",
      "+----+-------------------------------------+----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "airportsDF = spark.createDataFrame([\n",
    "    (\"JFK\", \"John F. Kennedy International Airport\", 1948),\n",
    "    (\"LIT\", \"Little Rock National Airport\", 1931),\n",
    "    (\"SEA\", \"Seattle-Tacoma International Airport\", 1949),\n",
    "], [\"IATA\", \"FullName\", \"Year\"])\n",
    "\n",
    "airportsDF.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+---------+----------+------+-----------+----+------------+-------+--------+-------+--------+---------+----------------+--------+-----------------+-------+--------+------------+------------+--------+-------------+-----------------+-----------+----+--------------------+----+\n",
      "|Month|DayofMonth|DayOfWeek|FlightDate|Origin| OriginCity|Dest|    DestCity|DepTime|DepDelay|ArrTime|ArrDelay|Cancelled|CancellationCode|Diverted|ActualElapsedTime|AirTime|Distance|CarrierDelay|WeatherDelay|NASDelay|SecurityDelay|LateAircraftDelay|ArrDelayCat|IATA|            FullName|Year|\n",
      "+-----+----------+---------+----------+------+-----------+----+------------+-------+--------+-------+--------+---------+----------------+--------+-----------------+-------+--------+------------+------------+--------+-------------+-----------------+-----------+----+--------------------+----+\n",
      "|    2|         1|        4|2018-02-01|   SEA|Seattle, WA| JFK|New York, NY|    733|    -2.0|   1526|   -38.0|      0.0|            null|     0.0|            293.0|  268.0|  2422.0|        null|        null|    null|         null|             null|       None| SEA|Seattle-Tacoma In...|1949|\n",
      "|    2|         2|        5|2018-02-02|   SEA|Seattle, WA| JFK|New York, NY|    727|    -8.0|   1506|   -58.0|      0.0|            null|     0.0|            279.0|  258.0|  2422.0|        null|        null|    null|         null|             null|       None| SEA|Seattle-Tacoma In...|1949|\n",
      "|    2|         3|        6|2018-02-03|   SEA|Seattle, WA| JFK|New York, NY|    729|    -6.0|   1529|   -35.0|      0.0|            null|     0.0|            300.0|  267.0|  2422.0|        null|        null|    null|         null|             null|       None| SEA|Seattle-Tacoma In...|1949|\n",
      "|    2|         4|        7|2018-02-04|   SEA|Seattle, WA| JFK|New York, NY|    732|    -3.0|   1551|   -13.0|      0.0|            null|     0.0|            319.0|  290.0|  2422.0|        null|        null|    null|         null|             null|       None| SEA|Seattle-Tacoma In...|1949|\n",
      "|    2|         5|        1|2018-02-05|   SEA|Seattle, WA| JFK|New York, NY|    729|    -6.0|   1524|   -40.0|      0.0|            null|     0.0|            295.0|  270.0|  2422.0|        null|        null|    null|         null|             null|       None| SEA|Seattle-Tacoma In...|1949|\n",
      "|    2|         6|        2|2018-02-06|   SEA|Seattle, WA| JFK|New York, NY|    726|    -9.0|   1532|   -32.0|      0.0|            null|     0.0|            306.0|  270.0|  2422.0|        null|        null|    null|         null|             null|       None| SEA|Seattle-Tacoma In...|1949|\n",
      "|    2|         7|        3|2018-02-07|   SEA|Seattle, WA| JFK|New York, NY|    725|   -10.0|   1536|   -28.0|      0.0|            null|     0.0|            311.0|  283.0|  2422.0|        null|        null|    null|         null|             null|       None| SEA|Seattle-Tacoma In...|1949|\n",
      "|    2|         8|        4|2018-02-08|   SEA|Seattle, WA| JFK|New York, NY|    729|    -6.0|   1507|   -57.0|      0.0|            null|     0.0|            278.0|  257.0|  2422.0|        null|        null|    null|         null|             null|       None| SEA|Seattle-Tacoma In...|1949|\n",
      "|    2|         9|        5|2018-02-09|   SEA|Seattle, WA| JFK|New York, NY|    727|    -8.0|   1508|   -56.0|      0.0|            null|     0.0|            281.0|  257.0|  2422.0|        null|        null|    null|         null|             null|       None| SEA|Seattle-Tacoma In...|1949|\n",
      "|    2|        10|        6|2018-02-10|   SEA|Seattle, WA| JFK|New York, NY|    727|    -8.0|   1523|   -41.0|      0.0|            null|     0.0|            296.0|  273.0|  2422.0|        null|        null|    null|         null|             null|       None| SEA|Seattle-Tacoma In...|1949|\n",
      "|    2|        11|        7|2018-02-11|   SEA|Seattle, WA| JFK|New York, NY|    728|    -7.0|   1608|     4.0|      0.0|            null|     0.0|            340.0|  311.0|  2422.0|        null|        null|    null|         null|             null|       None| SEA|Seattle-Tacoma In...|1949|\n",
      "|    2|        12|        1|2018-02-12|   SEA|Seattle, WA| JFK|New York, NY|    728|    -7.0|   1543|   -21.0|      0.0|            null|     0.0|            315.0|  284.0|  2422.0|        null|        null|    null|         null|             null|       None| SEA|Seattle-Tacoma In...|1949|\n",
      "|    2|        13|        2|2018-02-13|   SEA|Seattle, WA| JFK|New York, NY|    721|   -14.0|   1522|   -42.0|      0.0|            null|     0.0|            301.0|  282.0|  2422.0|        null|        null|    null|         null|             null|       None| SEA|Seattle-Tacoma In...|1949|\n",
      "|    2|        14|        3|2018-02-14|   SEA|Seattle, WA| JFK|New York, NY|    725|   -10.0|   1521|   -43.0|      0.0|            null|     0.0|            296.0|  270.0|  2422.0|        null|        null|    null|         null|             null|       None| SEA|Seattle-Tacoma In...|1949|\n",
      "|    2|         1|        4|2018-02-01|   SEA|Seattle, WA| PHX| Phoenix, AZ|    452|    -8.0|    832|   -25.0|      0.0|            null|     0.0|            160.0|  132.0|  1107.0|        null|        null|    null|         null|             null|       None| SEA|Seattle-Tacoma In...|1949|\n",
      "|    2|         2|        5|2018-02-02|   SEA|Seattle, WA| PHX| Phoenix, AZ|    457|    -3.0|    849|    -8.0|      0.0|            null|     0.0|            172.0|  139.0|  1107.0|        null|        null|    null|         null|             null|       None| SEA|Seattle-Tacoma In...|1949|\n",
      "|    2|         3|        6|2018-02-03|   SEA|Seattle, WA| PHX| Phoenix, AZ|    458|    -2.0|    841|   -16.0|      0.0|            null|     0.0|            163.0|  137.0|  1107.0|        null|        null|    null|         null|             null|       None| SEA|Seattle-Tacoma In...|1949|\n",
      "|    2|         4|        7|2018-02-04|   SEA|Seattle, WA| PHX| Phoenix, AZ|    452|    -8.0|    830|   -27.0|      0.0|            null|     0.0|            158.0|  142.0|  1107.0|        null|        null|    null|         null|             null|       None| SEA|Seattle-Tacoma In...|1949|\n",
      "|    2|         5|        1|2018-02-05|   SEA|Seattle, WA| PHX| Phoenix, AZ|    451|    -9.0|    832|   -25.0|      0.0|            null|     0.0|            161.0|  138.0|  1107.0|        null|        null|    null|         null|             null|       None| SEA|Seattle-Tacoma In...|1949|\n",
      "|    2|         6|        2|2018-02-06|   SEA|Seattle, WA| PHX| Phoenix, AZ|    451|    -9.0|    836|   -21.0|      0.0|            null|     0.0|            165.0|  137.0|  1107.0|        null|        null|    null|         null|             null|       None| SEA|Seattle-Tacoma In...|1949|\n",
      "+-----+----------+---------+----------+------+-----------+----+------------+-------+--------+-------+--------+---------+----------------+--------+-----------------+-------+--------+------------+------------+--------+-------------+-----------------+-----------+----+--------------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joinedFlightsDF = cleanFlightsDF.join(airportsDF, on=cleanFlightsDF.Origin == airportsDF.IATA, how=\"left_outer\")\n",
    "\n",
    "# PREGUNTA: mostrar algunas filas donde FullName no sea null\n",
    "joinedFlightsDF.where(\"FullName is not null\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-defined functions (UDFs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a construir un UDF para convertir millas a kilómetros. Ten en cuenta que esto podría hacerse fácilmente multiplicando directamente la columna de millas por 1.6 (y sería mucho más eficiente), ya que Spark permite el producto entre una columna y un número. En todos los casos en los que Spark proporciona funciones integradas para realizar una tarea (como esta), debes usar esas funciones y no una UDF. Las UDF deben emplearse solo cuando no hay otra opción.\n",
    "\n",
    "La razón es que las funciones integradas de Spark están optimizadas y Catalyst, el optimizador automático de código integrado en Spark, puede optimizarlo aún más. Sin embargo, las UDF son una caja negra para Catalyst y su contenido no se optimizará, y por lo tanto, generalmente son mucho más lentas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 60:======================================>                   (2 + 1) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+--------+------------------+\n",
      "|Origin|Dest|Distance|            DistKM|\n",
      "+------+----+--------+------------------+\n",
      "|   FAT| SFO|   158.0|             252.8|\n",
      "|   EWR| MYR|   550.0|             880.0|\n",
      "|   IAH| CLT|   912.0|            1459.2|\n",
      "|   BUF| EWR|   282.0|451.20000000000005|\n",
      "|   ROP| GUM|    56.0| 89.60000000000001|\n",
      "+------+----+--------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "# Primer paso: crear una función de Python que reciba UN número y lo multiplique por 1.6\n",
    "def milesToKm(miles):\n",
    "    return miles*1.6\n",
    "\n",
    "# Vamos a probarla\n",
    "print(milesToKm(5)) # 5 millas a km: 8 km\n",
    "\n",
    "# Segundo paso: crear un objeto UDF que envuelva a nuestra función. \n",
    "# Hay que especificar el tipo de dato que devuelve nuestra función\n",
    "udfMilesToKm = F.udf(milesToKm, DoubleType())\n",
    "\n",
    "# Con esto, Spark será capaz de llamar a nuestra función milesToKm sobre cada uno de los valores de una columna numérica.\n",
    "# Spark enviará el código de nuestra función a los executors a través de la red, y cada executor la ejecutará sobre las\n",
    "# particiones (una por una) que estén en ese executor\n",
    "\n",
    "# Tercer paso: vamos a probar la UDF añadiendo una nueva columna con el resultado de la conversión\n",
    "flightsWithKm = cleanFlightsDF.withColumn(\"DistKm\", udfMilesToKm(F.col(\"Distance\")))\n",
    "\n",
    "flightsWithKm = cleanFlightsDF.withColumn(\"DistKm\", 1.6 * F.col(\"Distance\"))\n",
    "\n",
    "\n",
    "flightsWithKm.select(\"Origin\", \"Dest\", \"Distance\", \"DistKM\")\\\n",
    "             .distinct()\\\n",
    "             .show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<p><b>BONUS</b>: Crea tu propia UDF que convierta DayOfWeek en una cadena.\n",
    "Puedes hacerlo creando una función de Python que reciba un número entero y devuelva el día de la semana,\n",
    "simplemente leyendo desde un vector de cadenas de longitud 7 el valor en la posición indicada por el argumento entero. Para la UDF, recuerda que tu función devuelve un StringType(). Finalmente, prueba tu UDF creando una nueva columna \"DayOfWeekString\".\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 63:======================================>                   (2 + 1) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+---------+---------------+\n",
      "|Origin|Dest|DayOfWeek|DayOfWeekString|\n",
      "+------+----+---------+---------------+\n",
      "|   BQK| ATL|        4|       Thursday|\n",
      "|   CVG| PHL|        3|      Wednesday|\n",
      "|   DTW| DFW|        5|         Friday|\n",
      "|   SEA| JFK|        2|        Tuesday|\n",
      "|   JAX| JFK|        2|        Tuesday|\n",
      "|   RDU| BOS|        3|      Wednesday|\n",
      "|   SEA| BOS|        3|      Wednesday|\n",
      "|   AUS| FLL|        3|      Wednesday|\n",
      "|   JFK| LAS|        5|         Friday|\n",
      "|   SLC| BOS|        6|       Saturday|\n",
      "|   BOS| HOU|        6|       Saturday|\n",
      "|   BDL| MCO|        7|         Sunday|\n",
      "|   SJU| TPA|        7|         Sunday|\n",
      "|   PGD| TYS|        6|       Saturday|\n",
      "|   PIE| CVG|        6|       Saturday|\n",
      "|   ABE| SFB|        7|         Sunday|\n",
      "|   LAS| BIS|        7|         Sunday|\n",
      "|   ROC| PGD|        1|         Monday|\n",
      "|   EWR| CVG|        1|         Monday|\n",
      "|   CVG| SFB|        1|         Monday|\n",
      "+------+----+---------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StringType\n",
    "\n",
    "from pyspark.sql import types as T\n",
    "\n",
    "# Primer paso: creamos una función de python que convierte un número entero en el día de la semana como cadena\n",
    "def dayOfWeekToString(dayInteger):\n",
    "    # En nuestros datos Monday es 1 pero las listas de python empiezan en el 0 y \n",
    "    # queremos usar el dayInteger como índice del vector\n",
    "    daysOfWeek = [\"\", \"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
    "    return daysOfWeek[dayInteger]\n",
    "    \n",
    "# Segundo paso: ajustamos nuestra función con un Spark UDF para que Spark pueda invocarlo en cada valor de una columna completa\n",
    "# De esta manera, Spark puede enviar nuestra función a los ejecutores, que eventualmente ejecutarán la función en las particiones\n",
    "# de los datos que tiene cada ejecutor\n",
    "dayOfWeekStringUDF = F.udf(dayOfWeekToString, T.StringType())\n",
    "\n",
    "# Tercer paso: intentemos nuestro UDF agregando una nueva columna que resulta de transformar (a través del UDF) el\n",
    "# columna existente DayOfWeek\n",
    "flightsWithDayOfWeekStr = cleanFlightsDF.withColumn(\"DayOfWeekString\", dayOfWeekStringUDF(F.col(\"DayOfWeek\")))\n",
    "\n",
    "flightsWithDayOfWeekStr.select(\"Origin\", \"Dest\", \"DayOfWeek\", \"DayOfWeekString\")\\\n",
    "                       .distinct()\\\n",
    "                       .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UDF con argumentos que no son columnas (usando currificación)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "def udf_currificada(param_config):\n",
    "    \"\"\"\n",
    "    El parámetro param_config configura si la función se comporta como suma o como producto. \n",
    "    Este parámetro no proviene de una columna del DF sino que lo indicamos nosotros de antemano\n",
    "    \"\"\"\n",
    "    def funcion_interna(x1, x2):\n",
    "        if param_config == \"suma\":\n",
    "            return x1+x2\n",
    "        elif param_config == \"producto\":\n",
    "            return x1*x2\n",
    "\n",
    "    # Envolvemos como UDF el objeto función junto al parámetro que hemos pasado. Aunque param_config\n",
    "    # es externo a la función \"funcion_interna\", dicho parámetro es necesario para ejecutar esa función y por\n",
    "    # tanto, forma parte de la \"clausura\" de la función interna: es un \"dato adjunto\" de la función interna\n",
    "    return F.udf(funcion_interna, DoubleType())\n",
    "\n",
    "\n",
    "def funcion_interna(tipo, x1, x2):\n",
    "    if tipo == \"suma\":\n",
    "        return x1+x2\n",
    "    elif tipo == \"producto\":\n",
    "        return x1*x2\n",
    "\n",
    "udf_para_usar = udf_currificada(\"producto\")\n",
    "\n",
    "cleanFlightsDF.where(\"ArrDelay is not null and DepDelay is not null\")\\\n",
    "              .select(udf_currificada(\"producto\")(F.col(\"ArrDelay\"), F.col(\"DepDelay\")).alias(\"suma_o_producto\"))\\\n",
    "              .show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
